---
title: "Visualisation Group Project"
author: "Anqian Li"
date: "11/22/2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE, message = FALSE,warning=FALSE}
# Load the tidyverse packages
library(tidyverse)
library(RColorBrewer)
library(patchwork)
library(wordcloud)
library(wordcloud2)
library(tm)
library(rgdal)
```


```{r}
listings <- read.csv("listings.csv")
reviews <- read.csv("reviews.csv")
calendar <- read.csv("calendar.csv")
```

#1. Data Cleaning
After browsing through the dataset for the listings, we decided to consider the listings with no review as inactive listings and drop them from our dataset. Also, since we are only focus on the listings information, we would drop the columns with the host information at this time.

```{r}
listings1 <- listings %>% filter(!is.na(review_scores_rating)) %>%
  select(-c(starts_with("host"), listing_url,
            scrape_id,last_scraped,name,picture_url))
```

#2. Exploratory Data Analysis
From the cleaned dataset, we can see that there are 53,693 listings in our dataset, and there are 33 neighbourhoods in the UK regions that offer airbnb listings in our dataset. Each listings are classified into 4 room types: "Entire home/apt", "private room", "Hotel room", and "Shared room".
```{r}
unique(listings1$neighbourhood_cleansed)
unique(listings1$room_type)
```

1. we want to first see how many listings in each neighborhoods and the roon type porprotion in each borough.
```{r}
listings1 %>% group_by(neighbourhood_cleansed) %>% 
  ggplot(aes(fct_rev(fct_infreq(neighbourhood_cleansed)),
             fill=room_type)) +
  geom_bar() + coord_flip() + labs(title ="Number of listings in each neighborhoods",
       x ="Neighborboods", fill = "Room Type")
```

- As we can see from the above plot, Westminster, Tower Hamlets, Hackney, Camden, and Kensington and Chelsea are the five regions that has most listings. And most of the listings are "Entire home/apt", followed by "private room". Since we are interested in purchasing a property and rent it on Airbnb entirely, we would use the listings that are entire home/apt and have bedroom number less then 4 for our reference.

```{r}
listings_entire <- listings1 %>% filter(room_type == "Entire home/apt", !is.na(bedrooms))
listings_entire$price <- as.numeric(sub('\\,','',sub('\\$','',listings_entire$price)))
listings_entire <- listings_entire %>% filter(bedrooms == 1)
listings_entire <- listings_entire %>% filter(price <= 400)
avg_prices <- listings_entire %>% group_by(neighbourhood_cleansed) %>% summarise(price=mean(price,na.rm = TRUE))
avg_prices$profits <- avg_prices$price * 365
avg_prices <- avg_prices %>% mutate(rank = rank(profits),
                      top = ifelse(rank > 23, "top ten", "others")) 

p_profits <- ggplot(data = avg_prices,aes(x=reorder(neighbourhood_cleansed,profits),y = profits,fill=top)) +geom_bar(stat="identity") + coord_flip() + labs(title ="Potential Profit per Neighborhood", x ="Neighborboods", fill="Profit Rank") + theme_bw()
p_profits

# ggsave("profit.png",height=7,width=7*1.5)
```

we can now see the number of listings again and the room number proportions.
```{r}
listings_entire$bedrooms <- as.factor(listings_entire$bedrooms)

p_count <- listings_entire %>% group_by(neighbourhood_cleansed) %>% 
  ggplot(aes(fct_rev(fct_infreq(neighbourhood_cleansed)),
             fill=bedrooms)) +
  geom_bar() + coord_flip() + labs(title ="Number of entire place listings in each neighborhood",
       x ="Neighborboods", fill = "# of bedrooms",
       y = "Number of listings")

p_count
```

- As we can see, for the listings that rented the entire property, the top five boroughs that have the most listings are now Westminster, Kensington and Chelsea, Camden, Tower Hamlets, and Hackney. Most listings have 1 bedrooms, followed by 2 bedrooms and 3 bedrooms.


2. Then we would like to see how the price behave in different neighbor
```{r}
listings_entire$price <- as.numeric(sub('\\,','',sub('\\$','',listings_entire$price)))
# as.numeric(substring(listings_entire$price, 2))
ggplot(listings_entire) + geom_histogram(aes(x=price))
summary(listings_entire$price)
```

As we can see there are a few listings that have price greater than 400 so we would consider the listings with price more than 400 as outliers and exclude them from our analysis.
```{r}
listings_400 <- listings_entire %>% filter(price <= 400)
p_price <- ggplot(data = listings_400,aes(x = fct_reorder(neighbourhood_cleansed,price), 
                               y = price, 
                               fill = neighbourhood_cleansed)) +
  geom_boxplot(outlier.shape=NA)  + coord_flip() + 
  theme(legend.position = "none") + 
  labs(title ="Price Range in each Neighborhood",
       x ="")
p_price

p_count + p_price
# ggsave("count_price.png",height=7,width=7*2.5)
```

- We can see from the above plot that the top 5 regions that have the highest average expensive listings are Kensington and Chelsea, Westminster, city of london, Camden, and Richmond upon Thames. 

- Compared of the number of listings in each neighborhood, Richmond upon Thames and city of london has relatively low number of listings but has a high average listing price. Kensington and Chelsea and Westminster have high number of listings and higher price.

3. visualise in map
```{r, warning=FALSE, message=FALSE}
london_boroughs <- readOGR(dsn = "LondonBoroughs.shp") 

summary_listing <- listings_400 %>% group_by(neighbourhood_cleansed) %>%
  summarise(ave_price = mean(price, na.rm = TRUE), 
            count = n(), 
            ave_rate_value = mean(review_scores_value, na.rm = TRUE),
            ave_rate_loc = mean(review_scores_location, na.rm = TRUE))

london_boroughs@data <- left_join(london_boroughs@data, summary_listing, by = c('name' = 'neighbourhood_cleansed'))

london_boroughs_f <- fortify(london_boroughs)

london_boroughs$id <- row.names(london_boroughs)
london_boroughs_f <- left_join(london_boroughs_f, london_boroughs@data) 

summary_name <- london_boroughs_f %>% group_by(name) %>% summarise(mean_long = mean(long), mean_lat = mean(lat))

p1 <- ggplot(london_boroughs_f, aes(long, lat, group = group, fill = ave_price)) +
  geom_polygon(size = 0.25,colour = "black") +
  scale_fill_gradientn(colors = brewer.pal(8,"Purples"))+
  theme_void() + labs(title="Average price in each neighborhood")

p2 <- ggplot(london_boroughs_f, aes(long, lat, group = group, fill = ave_rate_loc)) +
  geom_polygon(size = 0.25,colour = "black") + scale_fill_gradientn(colors = brewer.pal(8,"BuPu"))+
  theme_void() + labs(title="Average location review score in each neighborhood", fill = "location review score")+ geom_text(label="Richmond",mapping=aes(x=517567.5,y=173010.0))

p3 <- ggplot(london_boroughs_f, aes(long, lat, group = group, fill = ave_rate_value)) +
  geom_polygon(size = 0.25,colour = "black") + scale_fill_gradientn(colors = brewer.pal(8,"BuPu"))+
  theme_void() + labs(title="Average value review score in each neighborhood", fill = "value review score")+ geom_text(label="Richmond",mapping=aes(x=517567.5,y=173010.0))

p4 <- ggplot(london_boroughs_f, aes(long, lat, group = group, fill = count)) +
  geom_polygon(size = 0.25,colour = "black") + scale_fill_gradientn(colors = brewer.pal(8,"Purples"))+
  theme_void() + labs(title="Number of listings in each neighborhood")

(p1 | p2) / (p3 | p4)

p2 / p3
# ggsave("review map.png",height=6*2.5,width=6)
```

- As we can see from the above plots, most of the listings are around the center of london, and the average price of listings are also highest round the central london, which shows that central london seems to be the most preferable location (it is also indicated by the average location rate plot). However, based on the average rate on the value, central london seems to have a lower average rate than other places.

- Overall, if to travel to London, living in south part of London (i.e Kingston upon thames, richmond upon thames, merton, and Bromley) might be a better choice considering the location, price, and value of money. However, since the number of listings are limited in the south part of London, traveller might want to book their accomodation in advance.

- We would also want to look at the reviews to see if there are any potential reasons for customer giving low rate to central london.

4. review analysis
since we have 1,207,898 reviews in our dataset, which would be too large for R to handle, we decided to randomly select 10,000 reviews for our analysis.
```{r, warning=FALSE, message=FALSE}

set.seed(123)
index <- sample (c(1:1207898), size=10000, replace =F)

#Create a vector containing only the text
text <- reviews$comments[index]

# Create a corpus  
docs <- Corpus(VectorSource(text))

if (!require("pacman")) install.packages("pacman")
pacman::p_load(textstem)

docs <- lemmatize_words(docs)

docs <- docs %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, 
               c(stopwords("english"),"london","will","also","many",
                 "highly","just","bit","get", "stay","lovely","great",
                 "really","definitely"))

dtm <- TermDocumentMatrix(docs) 
matrix <- as.matrix(dtm) 
words <- sort(rowSums(matrix),decreasing=TRUE) 
df <- data.frame(word = names(words),freq=words)

set.seed(123) # for reproducibility 
wordcloud(words = df$word, freq = df$freq, min.freq = 1,
          max.words=200, random.order=FALSE,
          rot.per=0.35,colors=brewer.pal(8, "Dark2"))
```


- As we can see from the above word cloud, the keyword "host", "location", "station", "area", "clean" appeared a lot in the review comments, showing that most airbnb customer seems to take how their host behave during the stay as one of the major factors in rating. Also, people would consider the location of the listings, perhaps whether the listing is close to the station/metro/restaurants would affect the listing rate. 


5. Now we want to look at the availability of listings in calendar to try to find out the "busy" season next year.

```{r}
cat('We have', length(unique(calendar$date)), 'days and', length(unique(calendar$listing_id)), 'unique listings in the calendar data.')

min_date <- min(calendar$date)
max_date <- max(calendar$date)
min_date
max_date

calendar$available <- as.logical(toupper(calendar$available))

calendar$date <- as.Date(calendar$date)

calendar_available <- calendar %>% group_by(date) %>% summarise(ave_availability = mean(available, na.rm = TRUE))

p_ava <- ggplot(calendar_available, aes(x=date,y=ave_availability)) + 
  geom_line() +
  labs(title ="Availability of listings over time",
       x ="", y= "Availability ") + theme_bw()
p_ava
```

- As we can see from the availability plot, there is not many listings are available in October 2020, possibly due to the influence of the COVID-19 pandemic and the UK lockdown measure. The "busiest" season seems to be started from December to February in the next year, which would match with the Christmas holiday and the New Year time. The availability then decrease in March, and further decreases in May.


6. We then would like to see the price changes in time (seasonality and weekend strategy)

```{r}
x <- as.numeric(sub('\\,','',sub('\\$','',calendar$adjusted_price)))
calendar$adjusted_price <- x

calendar <- calendar %>% filter(!is.na(adjusted_price))

calendar_price <- calendar %>% 
  mutate(month = format(date, "%m")) %>% 
  group_by(month) %>% 
  summarise(ave_price = mean(adjusted_price, na.rm = TRUE))

calendar_price$month <- c(1:12)

p_month <- ggplot(calendar_price, aes(x=month,y=ave_price)) +
  geom_line() +scale_x_continuous(breaks=1:12) +
  labs(title ="Average Price change in month",
       x ="", y = "Average Price") +
  geom_text(label = c("lowest = 116.93"), aes(x = c(11), 
                                                y = c(116.5)),
                                                colour="red") +
  geom_text(label = c("highest = 130.42"), aes(x = c(7), 
                                                y = c(130.9)),
                                                colour="blue") +
  geom_point(aes(x=c(11),y=c(116.934)),color = "red",size=0.6) +
  geom_point(aes(x=c(7),y=c(130.4199)),color = "blue",size=0.6) +
  theme(legend.position = "none") + 
  theme_bw()

p_month
```

- We can see from the above plot that on average, the listing prices are higher in June, July, August and September, all with an average price above $128/night. The lowest price is in November then gradually increase in December.

```{r}
calendar <- calendar %>% mutate(weekday = weekdays(date))
calendar$weekday <- as.factor(calendar$weekday)

calendar$weekday <- factor(calendar$weekday, levels=c("Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"))

calendar_week <- calendar %>% group_by(weekday) %>% summarise(ave_price = mean(adjusted_price))

df <- data.frame(x=c(1:7),y = calendar_week$ave_price)

p_week <- ggplot(data = calendar_week,
       aes(x = weekday, y = ave_price)) +
  geom_point(size=0.6) + geom_line(df,mapping = aes(x=x,y=y)) +
  labs(title ="Average Price change in weekdays",
       x ="", y = "Average Price") +
  geom_text(label = c("lowest = 124.38"), aes(x = c(2), 
                                                y = c(124.5)),
                                                color="red") +
  geom_text(label = c("highest = 127.00"), aes(x = c(6.7), 
                                                y = c(127.1)),
                                                color="blue") +
  geom_point(aes(x=c(2),y=c(124.3773	)),color = "red",size=0.6) +
  geom_point(aes(x=c(7),y=c(126.9981)),color = "blue",size=0.6) +
  theme_bw()

p_week

(p_month + p_week) / p_ava
# ggsave("pricing strategy.png",height=6,width=6*1.7)
```

- As for the pricing in weekdays, hosts would generally set a higher price for Friday and Saturday, which makes sense because Friday and Saturday are the time when people finish a week's work for a trip. Sunday and Monday have the lowest prices, probably because people don't usually go on a trip at the beginning of the week, with a lower demand, hosts would hope to attract customer with a lower price.


```{r}
listings_entire <- listings1 %>% filter(room_type == "Entire home/apt", !is.na(bedrooms))

listings_entire$price <- as.numeric(sub('\\,','',sub('\\$','',listings_entire$price)))

listings_entire <- listings_entire %>% filter(bedrooms == 1)

listings_entire <- listings_entire %>% filter(price <= 400)

avg_prices <- listings_entire %>% group_by(neighbourhood_cleansed) %>% summarise(price=mean(price,na.rm = TRUE))

avg_prices$profits <- avg_prices$price * 365

avg_prices$neighbourhood_cleansed <- factor(avg_prices$neighbourhood_cleansed, levels=avg_prices$neighbourhood_cleansed[order(avg_prices$profits)])

p_profits <- ggplot(data = avg_prices,aes(x=fct_rev(fct_infreq(neighbourhood_cleansed)),y = profits)) +geom_bar(stat="identity") + coord_flip() + labs(title ="Number of listings in each neighborhoods", x ="Neighborboods", fill = "Room Type")

p_profits
```

```{r}
Islington <- listings_400 %>% filter(neighbourhood_cleansed == 'Islington')

length(unique(Islington$id)) # we have 1857 listings in Islington

unique_id <- Islington$id

calendar_islington <- calendar %>% filter(listing_id %in% unique_id)


calendar_islington$available <- as.logical(toupper(calendar_islington$available))

calendar_islington$date <- as.Date(calendar_islington$date)

x <- as.numeric(sub('\\,','',sub('\\$','',calendar_islington$adjusted_price)))
calendar_islington$adjusted_price <- x

calendar_islington <- calendar_islington %>% filter(!is.na(adjusted_price))

islington_price <- calendar_islington %>% 
  mutate(month = format(date, "%m")) %>% 
  group_by(month) %>% 
  summarise(ave_price = mean(adjusted_price, na.rm = TRUE))

islington_price$month <- c(1:12)

ggplot(islington_price, aes(x=month,y=ave_price)) +
  geom_line() +scale_x_continuous(breaks=1:12) +
  labs(title ="Average Price change in month",
       x ="", y = "Average Price") +
  # geom_text(label = c("lowest = 116.93"), aes(x = c(11), 
  #                                               y = c(116.5)),
  #                                               colour="red") +
  # geom_text(label = c("highest = 130.42"), aes(x = c(7), 
  #                                               y = c(130.9)),
  #                                               colour="blue") +
  # geom_point(aes(x=c(11),y=c(116.934)),color = "red",size=0.6) +
  # geom_point(aes(x=c(7),y=c(130.4199)),color = "blue",size=0.6) +
  theme(legend.position = "none") + 
  theme_bw()

```

```{r}
calendar_islington <- calendar_islington %>% mutate(weekday = weekdays(date))
calendar_islington$weekday <- as.factor(calendar_islington$weekday)

calendar_islington$weekday <- factor(calendar_islington$weekday, levels=c("Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"))

islington_week <- calendar_islington %>% group_by(weekday) %>% summarise(ave_price = mean(adjusted_price))

df <- data.frame(x=c(1:7),y = islington_week$ave_price)

ggplot(data = islington_week,
       aes(x = weekday, y = ave_price)) +
  geom_point(size=0.6) + geom_line(df,mapping = aes(x=x,y=y)) +
  labs(title ="Average Price change in weekdays",
       x ="", y = "Average Price") +
  # geom_text(label = c("lowest = 124.38"), aes(x = c(2), 
  #                                               y = c(124.5)),
  #                                               color="red") +
  # geom_text(label = c("highest = 127.00"), aes(x = c(6.7), 
  #                                               y = c(127.1)),
  #                                               color="blue") +
  # geom_point(aes(x=c(2),y=c(124.3773	)),color = "red",size=0.6) +
  # geom_point(aes(x=c(7),y=c(126.9981)),color = "blue",size=0.6) +
  theme_bw()

```

